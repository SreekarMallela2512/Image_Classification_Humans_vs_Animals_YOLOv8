{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d440b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.24.1-cp313-cp313-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: psutil in d:\\coding\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Collecting polars (from ultralytics)\n",
      "  Using cached polars-1.35.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\coding\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\coding\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\coding\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\coding\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\coding\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\coding\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\coding\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\coding\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\coding\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Collecting polars-runtime-32==1.35.2 (from polars->ultralytics)\n",
      "  Using cached polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl.metadata (1.5 kB)\n",
      "Using cached ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/110.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/110.9 MB 2.1 MB/s eta 0:00:53\n",
      "   ---------------------------------------- 1.0/110.9 MB 2.2 MB/s eta 0:00:51\n",
      "    --------------------------------------- 1.6/110.9 MB 2.3 MB/s eta 0:00:49\n",
      "    --------------------------------------- 2.1/110.9 MB 2.4 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 2.9/110.9 MB 2.6 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 3.7/110.9 MB 2.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 4.5/110.9 MB 2.9 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 5.2/110.9 MB 3.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 6.0/110.9 MB 3.2 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 7.1/110.9 MB 3.3 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 8.1/110.9 MB 3.5 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 8.9/110.9 MB 3.5 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 10.2/110.9 MB 3.8 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 11.5/110.9 MB 3.9 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 12.8/110.9 MB 4.0 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 13.9/110.9 MB 4.1 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 15.2/110.9 MB 4.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 16.3/110.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 17.6/110.9 MB 4.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 18.9/110.9 MB 4.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 20.4/110.9 MB 4.6 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 21.8/110.9 MB 4.7 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 23.1/110.9 MB 4.8 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 24.4/110.9 MB 4.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 25.7/110.9 MB 4.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 27.3/110.9 MB 5.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 28.6/110.9 MB 5.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 29.9/110.9 MB 5.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 31.2/110.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 32.5/110.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 33.6/110.9 MB 5.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 34.9/110.9 MB 5.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 36.2/110.9 MB 5.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 37.0/110.9 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 38.0/110.9 MB 5.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 39.1/110.9 MB 5.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 40.4/110.9 MB 5.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 41.4/110.9 MB 5.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 42.5/110.9 MB 5.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 44.0/110.9 MB 5.3 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 45.4/110.9 MB 5.3 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 46.4/110.9 MB 5.3 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 47.7/110.9 MB 5.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 48.8/110.9 MB 5.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 50.1/110.9 MB 5.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 51.1/110.9 MB 5.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 52.4/110.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 53.7/110.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 55.3/110.9 MB 5.4 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 56.6/110.9 MB 5.4 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 57.1/110.9 MB 5.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 58.2/110.9 MB 5.4 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 59.5/110.9 MB 5.4 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 60.6/110.9 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 61.9/110.9 MB 5.4 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 62.9/110.9 MB 5.4 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 64.2/110.9 MB 5.4 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 65.5/110.9 MB 5.4 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 66.8/110.9 MB 5.4 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 67.9/110.9 MB 5.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 68.9/110.9 MB 5.4 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 70.3/110.9 MB 5.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 71.6/110.9 MB 5.5 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 72.6/110.9 MB 5.5 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 73.9/110.9 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 75.2/110.9 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 76.0/110.9 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 77.3/110.9 MB 5.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 78.6/110.9 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 79.4/110.9 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 80.7/110.9 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 81.5/110.9 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 82.3/110.9 MB 5.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 83.6/110.9 MB 5.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 84.7/110.9 MB 5.4 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 85.7/110.9 MB 5.4 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 87.0/110.9 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 88.1/110.9 MB 5.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 89.1/110.9 MB 5.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 90.4/110.9 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 91.8/110.9 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 92.8/110.9 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 93.8/110.9 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 94.9/110.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 96.2/110.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 97.3/110.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 98.3/110.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 99.4/110.9 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.7/110.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 102.0/110.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.3/110.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 104.1/110.9 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 105.4/110.9 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.7/110.9 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 108.0/110.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.3/110.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.4/110.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 5.5 MB/s  0:00:20\n",
      "Downloading torchvision-0.24.1-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.4/4.3 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 5.9 MB/s  0:00:00\n",
      "Downloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Downloading polars-1.35.2-py3-none-any.whl (783 kB)\n",
      "   ---------------------------------------- 0.0/783.6 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 524.3/783.6 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 783.6/783.6 kB 3.6 MB/s  0:00:00\n",
      "Downloading polars_runtime_32-1.35.2-cp39-abi3-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/41.3 MB 6.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.1/41.3 MB 5.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.4/41.3 MB 6.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.7/41.3 MB 5.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.8/41.3 MB 5.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.8/41.3 MB 5.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.9/41.3 MB 5.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.2/41.3 MB 5.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.2/41.3 MB 5.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 11.5/41.3 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 12.8/41.3 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.9/41.3 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 15.2/41.3 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.5/41.3 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.8/41.3 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.1/41.3 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 20.4/41.3 MB 5.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.8/41.3 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.8/41.3 MB 5.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.9/41.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 24.6/41.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 25.7/41.3 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 27.0/41.3 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.3/41.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 29.6/41.3 MB 5.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.7/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 33.0/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.8/41.3 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.1/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.2/41.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.5/41.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/41.3 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.1/41.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 5.7 MB/s  0:00:07\n",
      "Installing collected packages: polars-runtime-32, opencv-python, torch, polars, ultralytics-thop, torchvision, ultralytics\n",
      "\n",
      "   ---------------------------------------- 0/7 [polars-runtime-32]\n",
      "   ---------------------------------------- 0/7 [polars-runtime-32]\n",
      "   ---------------------------------------- 0/7 [polars-runtime-32]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----- ---------------------------------- 1/7 [opencv-python]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------------- ---------------------- 3/7 [polars]\n",
      "   ----------------- ---------------------- 3/7 [polars]\n",
      "   ----------------- ---------------------- 3/7 [polars]\n",
      "   ---------------------- ----------------- 4/7 [ultralytics-thop]\n",
      "   ---------------------------- ----------- 5/7 [torchvision]\n",
      "   ---------------------------- ----------- 5/7 [torchvision]\n",
      "   ---------------------------- ----------- 5/7 [torchvision]\n",
      "   ---------------------------------- ----- 6/7 [ultralytics]\n",
      "   ---------------------------------- ----- 6/7 [ultralytics]\n",
      "   ---------------------------------- ----- 6/7 [ultralytics]\n",
      "   ---------------------------------- ----- 6/7 [ultralytics]\n",
      "   ---------------------------------------- 7/7 [ultralytics]\n",
      "\n",
      "Successfully installed opencv-python-4.12.0.88 polars-1.35.2 polars-runtime-32-1.35.2 torch-2.9.1 torchvision-0.24.1 ultralytics-8.3.228 ultralytics-thop-2.0.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bbe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"best_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af715c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Coding\\My Python Programs\\cat.jpeg: 480x640 3 animals, 269.6ms\n",
      "Speed: 2.7ms preprocess, 269.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference with the YOLOv8n model on the 'bus.jpg' image\n",
    "\n",
    "results = model(\"cat.jpeg\")\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae467bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Coding\\My Python Programs\\cat.jpeg: 480x640 1 animal, 297.4ms\n",
      "Speed: 2.8ms preprocess, 297.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[     59.287    0.097664      163.47      128.46]] [    0.99731] [          0]\n"
     ]
    }
   ],
   "source": [
    "results = model(\n",
    "    \"cat.jpeg\",\n",
    "    conf=0.45,         # try 0.4 -> 0.6\n",
    "    iou=0.45,          # NMS IoU threshold; try 0.3 -> 0.6\n",
    "    max_det=10,        # if you expect 1 object, set to 1\n",
    "    agnostic_nms=False # class-aware NMS (usually desired)\n",
    ")\n",
    "\n",
    "# inspect boxes\n",
    "boxes = results[0].boxes.xyxy.cpu().numpy()    # xyxy\n",
    "scores = results[0].boxes.conf.cpu().numpy()\n",
    "classes = results[0].boxes.cls.cpu().numpy()\n",
    "print(boxes, scores, classes)\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68377032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 human, 433.2ms\n",
      "Speed: 39.9ms preprocess, 433.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 380.2ms\n",
      "Speed: 3.9ms preprocess, 380.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 381.8ms\n",
      "Speed: 2.1ms preprocess, 381.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 350.1ms\n",
      "Speed: 2.3ms preprocess, 350.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 334.1ms\n",
      "Speed: 2.5ms preprocess, 334.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 333.3ms\n",
      "Speed: 3.0ms preprocess, 333.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 334.8ms\n",
      "Speed: 1.8ms preprocess, 334.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 331.4ms\n",
      "Speed: 2.8ms preprocess, 331.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 354.7ms\n",
      "Speed: 3.0ms preprocess, 354.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 320.8ms\n",
      "Speed: 2.6ms preprocess, 320.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 315.5ms\n",
      "Speed: 2.3ms preprocess, 315.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 330.5ms\n",
      "Speed: 2.2ms preprocess, 330.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 322.5ms\n",
      "Speed: 2.3ms preprocess, 322.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 319.7ms\n",
      "Speed: 2.3ms preprocess, 319.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 321.9ms\n",
      "Speed: 2.2ms preprocess, 321.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 321.4ms\n",
      "Speed: 2.4ms preprocess, 321.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 329.6ms\n",
      "Speed: 2.1ms preprocess, 329.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 325.3ms\n",
      "Speed: 2.5ms preprocess, 325.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 323.6ms\n",
      "Speed: 2.2ms preprocess, 323.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 320.1ms\n",
      "Speed: 2.5ms preprocess, 320.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 330.0ms\n",
      "Speed: 2.2ms preprocess, 330.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 325.2ms\n",
      "Speed: 1.6ms preprocess, 325.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 334.3ms\n",
      "Speed: 2.2ms preprocess, 334.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 327.9ms\n",
      "Speed: 2.8ms preprocess, 327.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 333.3ms\n",
      "Speed: 2.9ms preprocess, 333.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 344.6ms\n",
      "Speed: 2.1ms preprocess, 344.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 336.4ms\n",
      "Speed: 2.1ms preprocess, 336.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 330.0ms\n",
      "Speed: 2.4ms preprocess, 330.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 345.8ms\n",
      "Speed: 2.4ms preprocess, 345.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 369.5ms\n",
      "Speed: 5.7ms preprocess, 369.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 420.2ms\n",
      "Speed: 2.4ms preprocess, 420.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 animal, 1 human, 355.4ms\n",
      "Speed: 2.0ms preprocess, 355.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 368.8ms\n",
      "Speed: 2.2ms preprocess, 368.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 366.0ms\n",
      "Speed: 1.7ms preprocess, 366.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 385.6ms\n",
      "Speed: 3.5ms preprocess, 385.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 360.2ms\n",
      "Speed: 3.2ms preprocess, 360.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 333.5ms\n",
      "Speed: 2.1ms preprocess, 333.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 359.6ms\n",
      "Speed: 2.1ms preprocess, 359.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 426.6ms\n",
      "Speed: 2.8ms preprocess, 426.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 403.0ms\n",
      "Speed: 3.1ms preprocess, 403.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 389.9ms\n",
      "Speed: 2.0ms preprocess, 389.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 357.6ms\n",
      "Speed: 2.9ms preprocess, 357.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 330.8ms\n",
      "Speed: 2.7ms preprocess, 330.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 374.8ms\n",
      "Speed: 2.2ms preprocess, 374.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Run YOLO inference\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, iou\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.45\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Draw results\u001b[39;00m\n\u001b[0;32m     23\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()   \u001b[38;5;66;03m# YOLO draws boxes automatically\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:182\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    156\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    157\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    159\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    This method simplifies the process of making predictions by allowing the model instance to be called directly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:540\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:328\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 328\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:658\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 658\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:137\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:154\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:176\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 176\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    177\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:307\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    305\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    306\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:89\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32md:\\Coding\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    545\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model = YOLO(\"best_1.pt\")   # path to your weights file\n",
    "\n",
    "# Open webcam (0), or change to video path like \"video.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set resolution (optional)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model(frame, conf=0.4, iou=0.45)\n",
    "\n",
    "    # Draw results\n",
    "    annotated_frame = results[0].plot()   # YOLO draws boxes automatically\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLOv8 Live Detection\", annotated_frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db16b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
